#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Hydra
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–∞—Ö: .ckpt (PyTorch Lightning), .onnx, .engine/.trt (TensorRT)
"""

import os
import warnings
from pathlib import Path

import hydra
import numpy as np
import pandas as pd
import torch
from omegaconf import DictConfig, OmegaConf
from PIL import Image
from tqdm import tqdm

from butterfly_classification.train_pipeline.dataset import get_transforms
from butterfly_classification.train_pipeline.model_loader import load_model

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore")


def predict_single_image(model_wrapper, image_path, transform, class_names):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é."""

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    image = Image.open(image_path).convert("RGB")
    image_tensor = transform(image).unsqueeze(0)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    outputs = model_wrapper.predict(image_tensor)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if isinstance(outputs, np.ndarray):
        outputs = torch.from_numpy(outputs)

    # –í—ã—á–∏—Å–ª—è–µ–º softmax –∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    probabilities = torch.softmax(outputs, dim=1)
    predicted_class_idx = torch.argmax(probabilities, dim=1).item()
    confidence = probabilities[0, predicted_class_idx].item()

    predicted_class = class_names[predicted_class_idx]

    return predicted_class, confidence, probabilities[0].cpu().numpy()


def predict_test_dataset(cfg: DictConfig):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞."""

    if cfg.logging.verbose:
        print("=" * 50)
        print("ü¶ã BUTTERFLY CLASSIFICATION PREDICTIONS ü¶ã")
        print("=" * 50)
        print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:\n{OmegaConf.to_yaml(cfg)}")

    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    output_dir = Path(cfg.output.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
    if cfg.logging.verbose:
        print(" –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ {}".format(cfg.model.checkpoint_path))

    try:
        model_wrapper = load_model(cfg.model.checkpoint_path)

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = model_wrapper.get_model_info()
        if cfg.logging.verbose:
            print("–¢–∏–ø –º–æ–¥–µ–ª–∏: {}".format(model_info["model_type"]))
            print("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {}".format(model_info["device"]))
            print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {}".format(model_info["num_classes"]))

            if model_info["model_type"] == "onnx":
                print("ONNX –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {}".format(model_info["providers"]))
            elif model_info["model_type"] == "tensorrt":
                print(
                    "TensorRT –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π batch size: {}".format(
                        model_info.get("max_batch_size", "–Ω–µ —É–∫–∞–∑–∞–Ω")
                    )
                )

    except Exception as e:
        print("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {}".format(e))
        return None

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
    class_names = model_wrapper.class_names
    if not class_names:
        # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
        class_names = [f"Class_{i}" for i in range(model_info["num_classes"] or 75)]

    # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏/—Ç–µ—Å—Ç–∞)
    transform = get_transforms(train=False)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    test_df = pd.read_csv(cfg.data.test_csv)
    if cfg.logging.verbose:
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(test_df)}")

    # –ì–æ—Ç–æ–≤–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    predictions = []
    confidences = []
    all_probabilities = []

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–æ–≤—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    if cfg.logging.verbose:
        print("–î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")

    iterator = (
        tqdm(test_df.iterrows(), total=len(test_df))
        if cfg.processing.show_progress
        else test_df.iterrows()
    )

    for idx, row in iterator:
        filename = row["filename"]
        image_path = Path(cfg.data.test_images_dir) / filename

        if image_path.exists():
            try:
                pred_class, confidence, probs = predict_single_image(
                    model_wrapper, image_path, transform, class_names
                )
                predictions.append(pred_class)
                confidences.append(confidence)
                all_probabilities.append(probs)
            except Exception as e:
                if cfg.logging.verbose:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {filename}: {e}")
                predictions.append("UNKNOWN")
                confidences.append(0.0)
                all_probabilities.append(np.zeros(len(class_names)))
        else:
            if cfg.logging.verbose:
                print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}")
            predictions.append("UNKNOWN")
            confidences.append(0.0)
            all_probabilities.append(np.zeros(len(class_names)))

    # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    results_df = test_df.copy()
    results_df["predicted_class"] = predictions
    results_df["confidence"] = confidences

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    saved_files = []

    if cfg.output.create_detailed_results:
        results_path = output_dir / "predictions.csv"
        results_df.to_csv(results_path, index=False)
        saved_files.append(str(results_path))
        if cfg.logging.verbose:
            print(f"–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_path}")

    if cfg.output.create_submission:
        submission_df = pd.DataFrame(
            {"filename": test_df["filename"], "label": predictions}
        )
        submission_path = output_dir / "submission.csv"
        submission_df.to_csv(submission_path, index=False)
        saved_files.append(str(submission_path))
        if cfg.logging.verbose:
            print(f"–§–∞–π–ª –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏: {submission_path}")

    if cfg.output.create_probabilities:
        probs_df = pd.DataFrame(all_probabilities, columns=class_names)
        probs_df["filename"] = test_df["filename"]
        probs_path = output_dir / "probabilities.csv"
        probs_df.to_csv(probs_path, index=False)
        saved_files.append(str(probs_path))
        if cfg.logging.verbose:
            print(f"–î–µ—Ç–∞–ª—å–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {probs_path}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    if cfg.logging.show_statistics and cfg.logging.verbose:
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (—Ç–æ–ø-{cfg.logging.top_k_stats}):")
        pred_stats = pd.Series(predictions).value_counts().head(cfg.logging.top_k_stats)
        for class_name, count in pred_stats.items():
            percentage = (count / len(predictions)) * 100
            print(f"  {class_name}: {count} ({percentage:.1f}%)")

    if cfg.logging.verbose:
        print("\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
        print(f"–í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
        for file_path in saved_files:
            print(f"  - {file_path}")

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        model_type = model_wrapper.model_type
        if model_type == "onnx":
            print("–ú–æ–¥–µ–ª—å ONNX –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        elif model_type == "tensorrt":
            print("–ú–æ–¥–µ–ª—å TensorRT –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ GPU")
        else:
            print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ PyTorch Lightning –º–æ–¥–µ–ª—å")

    return results_df


def predict_single_image_mode(cfg: DictConfig):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""

    if cfg.logging.verbose:
        print("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    try:
        model_wrapper = load_model(cfg.model.checkpoint_path)

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = model_wrapper.get_model_info()
        if cfg.logging.verbose:
            print(f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {model_info['model_type']}")
            print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {model_info['device']}")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None, None

    # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    transform = get_transforms(train=False)

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
    class_names = model_wrapper.class_names
    if not class_names:
        class_names = [f"Class_{i}" for i in range(75)]

    # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    pred_class, confidence, _ = predict_single_image(
        model_wrapper, cfg.data.single_image, transform, class_names
    )

    if cfg.logging.verbose:
        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {cfg.data.single_image}")
        print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {pred_class}")
        print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")
        print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {model_wrapper.device}")
        print(f"–§–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏: {model_wrapper.model_type}")

    return pred_class, confidence


@hydra.main(
    version_base=None, config_path="../../configs", config_name="predict_config"
)
def main(cfg: DictConfig) -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π."""

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ checkpoint —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not os.path.exists(cfg.model.checkpoint_path):
        print(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {cfg.model.checkpoint_path}")
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏
    model_extension = Path(cfg.model.checkpoint_path).suffix.lower()
    supported_formats = [".ckpt", ".onnx", ".engine", ".trt", ".pth", ".pt"]

    if model_extension not in supported_formats:
        print(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏: {model_extension}")
        print(f"   –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(supported_formats)}")
        return

    if cfg.logging.verbose:
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç –º–æ–¥–µ–ª–∏: {model_extension}")

    if cfg.data.single_image:
        # –†–µ–∂–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if not os.path.exists(cfg.data.single_image):
            print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {cfg.data.single_image}")
            return
        predict_single_image_mode(cfg)
    else:
        # –†–µ–∂–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        if not os.path.exists(cfg.data.test_csv):
            print(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {cfg.data.test_csv}")
            return
        if not os.path.exists(cfg.data.test_images_dir):
            print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {cfg.data.test_images_dir}")
            return
        predict_test_dataset(cfg)


if __name__ == "__main__":
    main()
